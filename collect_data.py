import cv2
import os
import time
import numpy as np
from utils.mediapipe_utils import MediaPipeHandTracker
from utils.data_utils import DataProcessor

class DataCollector:
    def __init__(self):
        """Khá»Ÿi táº¡o DataCollector"""
        self.hand_tracker = MediaPipeHandTracker()
        self.data_processor = DataProcessor()
        
        # CÃ¡c tham sá»‘ thu tháº­p
        self.total_frames = 30  # ChÃ­nh xÃ¡c 30 frame
        self.fps = 20  # FPS cá»§a video
        
        # CÃ¡c lá»›p dáº¥u thanh
        self.classes = self.data_processor.classes
        self.class_names = self.data_processor.class_names
        
        # Tráº¡ng thÃ¡i hiá»‡n táº¡i
        self.current_class = 0  # Index cá»§a lá»›p hiá»‡n táº¡i
        self.is_recording = False
        self.recording_frames = []
        self.frame_count = 0
        
        # Thá»‘ng kÃª
        self.stats = self.data_processor.get_data_statistics()
        
        print("=== Há»† THá»NG THU THáº¬P Dá»® LIá»†U Dáº¤U THANH ===")
        print(f"Sá»‘ frame: {self.total_frames}")
        print(f"FPS: {self.fps}")
        print("CÃ¡c lá»›p dáº¥u thanh:")
        for i, (cls, name) in enumerate(self.class_names.items(), 1):
            print(f"  {i}. {cls}: {name}")
        print("\nÄIá»€U KHIá»‚N:")
        print("  1-5: Chá»n dáº¥u thanh")
        print("  SPACE: Báº¯t Ä‘áº§u thu tháº­p")
        print("  Q: ThoÃ¡t")
    
    def get_next_sample_id(self, class_name: str) -> int:
        """Láº¥y ID máº«u tiáº¿p theo cho lá»›p"""
        class_dir = os.path.join(self.data_processor.keypoints_dir, class_name)
        if not os.path.exists(class_dir):
            return 0
        
        existing_samples = [f for f in os.listdir(class_dir) if f.endswith('.npy')]
        return len(existing_samples)
    
    def start_recording(self):
        """Báº¯t Ä‘áº§u thu tháº­p video"""
        if self.is_recording:
            return
        
        self.is_recording = True
        self.recording_frames = []
        self.frame_count = 0
        self.sample_id = self.get_next_sample_id(self.classes[self.current_class])
        print(f"\nðŸŽ¬ Báº¯t Ä‘áº§u thu tháº­p {self.class_names[self.classes[self.current_class]]} (ID: {self.sample_id})")
    
    def stop_recording(self):
        """Dá»«ng thu tháº­p video"""
        if not self.is_recording:
            return
        self.is_recording = False
        if len(self.recording_frames) == self.total_frames:
            class_name = self.classes[self.current_class]
            # Sá»­ dá»¥ng numpy array Ä‘á»ƒ giáº£m overhead khi lÆ°u
            frames_array = np.stack(self.recording_frames)
            self.data_processor.save_keypoints(frames_array, class_name, self.sample_id)
            self.stats[class_name] += 1
            self.stats['total'] += 1
            print(f"âœ… ÄÃ£ lÆ°u {len(self.recording_frames)} frames cho {self.class_names[class_name]} (ID: {self.sample_id})")
        else:
            print(f"âŒ Thu tháº­p khÃ´ng thÃ nh cÃ´ng! Chá»‰ cÃ³ {len(self.recording_frames)} frames")
        self.recording_frames.clear()
        self.frame_count = 0

    def process_frame(self, frame):
        """Xá»­ lÃ½ frame vÃ  trÃ­ch xuáº¥t keypoints"""
        keypoints = self.hand_tracker.extract_keypoints(frame)
        # Sá»­ dá»¥ng biáº¿n static cho frame trá»‘ng Ä‘á»ƒ trÃ¡nh táº¡o má»›i liÃªn tá»¥c
        if not hasattr(self, '_empty_keypoints'):
            self._empty_keypoints = np.zeros(63)
        if keypoints is not None:
            frame = self.hand_tracker.draw_landmarks(frame, keypoints)
            if self.is_recording:
                self.recording_frames.append(keypoints)
                self.frame_count += 1
        else:
            if self.is_recording:
                self.recording_frames.append(self._empty_keypoints)
                self.frame_count += 1
        return frame
    
    def draw_ui(self, frame):
        """Váº½ giao diá»‡n ngÆ°á»i dÃ¹ng lÃªn frame"""
        # ThÃ´ng tin lá»›p hiá»‡n táº¡i
        current_class_name = self.class_names[self.classes[self.current_class]]
        cv2.putText(frame, f"Dau thanh: {current_class_name}", (10, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # Thá»‘ng kÃª lá»›p hiá»‡n táº¡i
        current_count = self.stats.get(self.classes[self.current_class], 0)
        cv2.putText(frame, f"Label: {current_count}", (10, 90), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # Tráº¡ng thÃ¡i thu tháº­p
        if self.is_recording:
            cv2.putText(frame, f"Thu tháº­p: {self.frame_count}/{self.total_frames}", (10, 120), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # Váº½ progress bar
            progress = self.frame_count / self.total_frames
            bar_width = 200
            bar_height = 20
            bar_x, bar_y = 10, 150
            
            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (128, 128, 128), 2)
            fill_width = int(bar_width * progress)
            cv2.rectangle(frame, (bar_x, bar_y), (bar_x + fill_width, bar_y + bar_height), (0, 255, 0), -1)
            
            if self.frame_count >= self.total_frames:
                cv2.putText(frame, "HoÃ n thÃ nh!", (10, 190), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            cv2.putText(frame, "Enter Space to begin:", (10, 120), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # Danh sÃ¡ch cÃ¡c lá»›p
        y_offset = 220
        for i, (cls, name) in enumerate(self.class_names.items()):
            color = (0, 255, 0) if i == self.current_class else (128, 128, 128)
            count = self.stats.get(cls, 0)
            cv2.putText(frame, f"{i+1}. {name}: {count} máº«u", (10, y_offset + i*25), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
        
        
        # Tá»•ng thá»‘ng kÃª
        cv2.putText(frame, f"Total: {self.stats['total']} mau", (10, 470), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
    
    def run(self):
        """Cháº¡y há»‡ thá»‘ng thu tháº­p dá»¯ liá»‡u"""
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("KhÃ´ng thá»ƒ má»Ÿ camera!")
            return
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        cap.set(cv2.CAP_PROP_FPS, self.fps)
        print("Báº¯t Ä‘áº§u hiá»ƒn thá»‹ camera...")
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                frame = self.process_frame(frame)
                self.draw_ui(frame)
                if self.is_recording and self.frame_count >= self.total_frames:
                    self.stop_recording()
                cv2.imshow('Thu tháº­p dá»¯ liá»‡u dáº¥u thanh', frame)
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    break
                elif key == ord(' '):
                    if not self.is_recording:
                        self.start_recording()
                elif key in [ord('1'), ord('2'), ord('3'), ord('4'), ord('5')]:
                    class_idx = key - ord('1')
                    if 0 <= class_idx < len(self.classes):
                        self.current_class = class_idx
                        print(f"ÄÃ£ chá»n: {self.class_names[self.classes[self.current_class]]}")
        finally:
            cap.release()
            cv2.destroyAllWindows()
            print(f"\n=== THá»NG KÃŠ CUá»I CÃ™NG ===")
            for cls in self.classes:
                print(f"  {self.class_names[cls]}: {self.stats[cls]} máº«u")
            print(f"Tá»•ng cá»™ng: {self.stats['total']} máº«u")

def main():
    """HÃ m chÃ­nh"""
    collector = DataCollector()
    collector.run()

if __name__ == "__main__":
    main()